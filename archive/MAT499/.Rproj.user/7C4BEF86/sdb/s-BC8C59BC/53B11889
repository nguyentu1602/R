{
    "contents" : "install.packages('multicore')\ninstall.packages('foreach')\ninstall.packages('biglm')\ninstall.packages('bigmemory')\ninstall.packages('doParallel')\ninstall.packages('parallel')\ninstall.packages('doMC')\ninstall.packages('ggplot2')\ninstall.packages('sampling')\n\nrequire(foreach)\nrequire(multicore)\nrequire(biglm)\nrequire(bigmemory)\nrequire(doParallel)\nrequire(doMC)\nrequire(igraph)\nrequire(ggplot2)\nrequire(sampling)\n\n# declare global variable\nlag <- 40\n\n\n\n### hash() and unHash() are functions to create hashCode\n\nhash <- function (x, y) {\n  if (x == max(x,y)){\n    return (x^2 + x + y);}\n  else\n    {return (x + y^2);}\n}\n\nunHash <- function (z) {\n  if ( (z - (trunc(sqrt(z)))^2) < trunc(sqrt(z)) ) {\n    return ( c(z - (trunc(sqrt(z)))^2, trunc(sqrt(z))) ); \n  }\n  else {\n    return ( c(trunc(sqrt(z)), z - (trunc(sqrt(z)))^2 - (trunc(sqrt(z)))) ); \n  }\n} #unHash\n\n\n# Testing hash() and unHash()\n# Note: it gives wrong round-off when we have (10^8, 10^8), but anything less works \n# v1 <- c(1:10000000)\n# v2 <- seq(from=10000000,to=1,by=-1)\n# v2\n# v3 <- c(1:10000000)\n# \n# for (i in 1:10000000) {\n#   temp = unHash(hash(v1[i], v2[i])) - c(v1[i], v2[i])\n#   v3[i] = !((temp[1] == 0) && (temp[2] == 0))\n# }\n\n\n\n### Load all the files at once:\n\n#setwd('/Users/cuongnguyen/Dropbox/00.Class/0.S14/MAT499/as-caida/')\n#dataFiles <- lapply(Sys.glob(\"as-caida*.txt\"), read.table)\n#head(dataFiles[[1]])\n\n### Manipulate the data:\n# Erase all 1: Provider->Customer is an invalid direction\n# Change all 2 into 0: siblings are the same as p2p\n# Change all -1 to 1: Customer->Provider should cost 1 per move\n\n# for (i in 1:length(dataFiles)) {\n# dataFiles[[i]]  <- subset(dataFiles[[i]] , V3!=1) # Erase all 1s\n# dataFiles[[i]]$V3 = dataFiles[[i]]$V3 %% 2 # Change all -1s to 1s and all 2s to 0\n# names(dataFiles[[i]]) = c('fromNode','toNode', 'weight') \n} # The dataFiles list is now cleaned and suitable for our purpose\n\n### Saving the data;\nsave(dataFiles,file=\"as-caida-cleaned.R\")\nload('/Users/cuongnguyen/Dropbox/00.Class/0.S14/MAT499/as-caida/as-caida-cleaned.R')\n# load('~/csc207/Git/mat499/as-caida-cleaned.R')\n\nrm(dataFiles)\nrequire(igraph)\n### Load the dataFiles into a list of graphs\ngraphList <- list()\ngraphList[[1]] <- graph.data.frame(dataFiles[[1]], directed = TRUE)\ngraphList[[1]]\n\n\n<<<<<<< Updated upstream\n=======\ndegree(graph=graphList[[1]], v=1000, mode=\"in\" )\n\nsystem.time(graphList <- lapply(dataFiles, graph.data.frame))\n>>>>>>> Stashed changes\nsystem.time(graphList <- mclapply(dataFiles, graph.data.frame))\n\n# Get all edges list\nedgeListStr <- mclapply(graphList, get.edgelist)\nlength(edgeListStr)\n\n#edgeList <- mclapply(edgeList, function (mat) {cbind(mat, paste(mat[,1], mat[,2]))})\nedgeList <- list()\nedgeList <- mclapply(edgeListStr, function (mat) {\n  return( cbind (as.numeric(mat[,1]), as.numeric(mat[,2])));})\n\nedgeList[[1]]\n\n# Created a list of 122 vectors, each containing hashcodes of all the edges\n\nID <- list()\nsystem.time(ID <- mclapply(edgeList, \n                           function (mat) {\n                             v <- vector(mode=\"numeric\", length=length(mat[,1])); \n                             for (i in 1:length(mat[,1])) {\n                               v[i] = hash(mat[i,1], mat[i,2])};\n                             return (v)}) )\n\nedgeList\n\n# Created a list of 122-1 vectors of response variable Y: was it in the next graph\nY <- list()\npercentSurvive <- vector(length=121-lag)\n\nfor (i  in 1:(length(ID) - lag)) {         \n  Y[[i]] = (ID[[i+lag-1]] %in% ID[[i+lag]]); # which edges in G20 are still in G21\n  percentSurvive[i] = sum(Y[[i]])/length(Y[[i]]);\n}\n\n# A graph showing survivor rate over time\nplot(percentSurvive,ylim=c(0.1,1) )\n# Very interesting that the survival date for 20070917 is only 35% - I might have to left out 8 last graphs\n\n??reset\n??refresh\n\n\n# Create the feature matrix -----------------------------------------------\n\nX <- list()\nregisterDoMC(cores=4)\n\nsystem.time (for (i in 1:10) {\n  X[[i]] = matrix(data=NA,nrow=length(ID[[lag-1+i]]),ncol=100);\n}  \n)\n\nX[[1]]\n\n#Check the length of the lag-th edgelist and the # of rows of first matrix in X \nlength(X[[1]][,1]) - length(ID[[lag]])\n\n#For X[[1]], extracting x1 -> x(lag-1): was it in the last (lag-1) graphs?\nfor (j in 1:10) {\n  for (i in 1:(lag-1)) {  # loop through lag-1 previous graphs \n    X[[j]][,i] = ID[[lag-1+j]] %in% ID[[i+j-1]];\n  }}\n\n# Testing x1 -> x(lag-1)\nsum(X[[7]][,lag-1])/length(X[[7]][,lag-1])\n\n# Now get the weights for the nodes, put in x20\nsummary(graphList[[lag]])\n  # Trick to name only one column:\ncolnames(X[[1]]) <- 1:dim(X[[1]])[2]\ncolnames(X[[1]])[lag:(lag+7)] <- c(\"weight\",'fromInDegree', 'fromOutDegree', 'toInDegree',\n                            'toOutDegree','fromCloseness', 'toCloseness', 'betweeness')\nX[[1]][,lag] <- get.edge.attribute(graph=graphList[[lag]],name=\"weight\")\n# Degrees:\nX[[1]][,lag+1] <- degree(graph=graphList[[lag]],v=edgeListStr[[lag]][,1],mode='in')\nX[[1]][,lag+2] <- degree(graph=graphList[[lag]],v=edgeListStr[[lag]][,1],mode='out')\nX[[1]][,lag+3] <- degree(graph=graphList[[lag]],v=edgeListStr[[lag]][,2],mode='in')\nX[[1]][,lag+4] <- degree(graph=graphList[[lag]],v=edgeListStr[[lag]][,2],mode='out')\n\n# alpha.centrality crash my workstation last time. It collides with \"multicore\" package too\n#X[[1]][,25] <- alpha.centrality(graph=graphList[[20]],nodes=edgeListStr[[20]][,1])\nX[[1]][,lag+5] <- closeness(graph=graphList[[lag]],vids=edgeListStr[[lag]][,1],mode=c('out','in','all','total'))\nX[[1]][,lag+6] <- closeness(graph=graphList[[lag]],vids=edgeListStr[[lag]][,2],mode=c('out','in','all','total'))\n\nhead(X[[1]])\n\n# Betweeness\nX[[1]][,lag+7] <- edge.betweenness(graph=graphList[[lag]],e=E(graphList[[lag]]),directed=TRUE, weights = NULL)\n\n# Done extracting the first 47 features: First 39 columns are presence in the first 39 graphs. \n\n\n# Advance features of switching of node ------------------------------------\n\ncolnames(X[[1]])[(lag+8): (lag+10)] <- c(\"percentOf'1'\",'countOfSwitch','timeUntilLast1')\nhead(X[[1]])\n# X[[1]][,lag+8] : counts of 1s in the previous 39 column\nX[[1]][,lag+8] <- rowSums(X[[1]][,1:(lag-1)])/(lag-1)\n\n# X[[1]][,lag+9] :number of switch in the previous 39 column\n # create a function to take in a matrix of size 39, then return a vector of number of switch\nswitchCount <- function (mat) {\n  len <- length(mat[,1]);\n  ncol <- length(mat[1,]);\n  # Make a buffered matrix:\n  switchMat <- matrix(nrow=len, ncol=ncol);\n  \n  # For loop to catch number of switch\n  for (i in 1: (ncol-1)) {\n    switchMat[,i] <- abs(mat[,i+1]-mat[,i]);\n  }\n  switchMat[,ncol] <- rowSums(switchMat[,1:(ncol-1)]);\n  return (switchMat[,ncol]);\n}\n\nX[[1]][,lag+9] <- switchCount(X[[1]][,1:39])\n\nhead(X[[1]])\n# X[[1]][,lag+10] :time to the closet 0, i.e. how long this node has been alive stably\n# write a function to take a vector and count back ward until it reaches the first 0\ncountFirstZero <- function (vec) {\n  i <- length(vec);\n  while ((vec[i] > 0) && (i >= 1)) {\n    i <- i - 1;\n  }\n  return (length(vec) - i);\n}\n\n\ncountFirstZero (X[[1]][10,1:39])\nX[[1]][10,1:39]\n\n# Two ways: A for loop and apply() give the same result:\n # For loop\nfor(k in 1:length(X[[1]][,1]) ) {\n  X[[1]][k,lag+10] <- countFirstZero (X[[1]][k,1:39]);  \n}\n  # apply()  \nX[[1]][,lag+10] <- apply(X[[1]][,1:39] , MARGIN=1, FUN=countFirstZero)\nhead(X[[1]])\n\n\n# Extracting new features -------------------------------------------------\n\n  # New features 1-4: column lag+11 to 14: \n\ncolnames(X[[1]])[(lag+11): (lag+14)] <- c(\"fromInDegreeLag1\",'fromOutDegreeLag1','toInDegreeLag1', \"toOutDegreeLag1\")\n\nhead(edgeListStr[[lag-1]])\n\n# Create a temp vector for fromInDegreeLag1 and fromOutDegreeLag1\nhead(X[[1]])\n\ntempFrom <- cbind( unique(edgeListStr[[lag-1]][,1]),\n               degree(graph=graphList[[lag-1]],v=unique(edgeListStr[[lag-1]][,1]),mode='in',),\n               degree(graph=graphList[[lag-1]],v=unique(edgeListStr[[lag-1]][,1]),mode='out')\n            )\n\n\ntempTo <- cbind( unique(edgeListStr[[lag-1]][,2]),\n                   degree(graph=graphList[[lag-1]],v=unique(edgeListStr[[lag-1]][,2]),mode='in',),\n                   degree(graph=graphList[[lag-1]],v=unique(edgeListStr[[lag-1]][,2]),mode='out')\n)\npositionFrom <- match(edgeListStr[[lag]][,1], tempFrom[,1], nomatch=0)\npositionTo <- match(edgeListStr[[lag]][,2], tempTo[,1], nomatch=0)\npositionFrom[2]\n\nis.vector(tempFrom[1,2:3])\n\n\nfor (i in 1:length(positionFrom)) {\n  if (positionFrom[i] != 0) {\n    X[[1]][i,(lag+11):(lag+12)] <- as.numeric(tempFrom[positionFrom[i],2:3])\n  }\n  else {X[[1]][i,(lag+11):(lag+12)] <- 0}\n  \n  if (positionTo[i] != 0) {\n    X[[1]][i,(lag+13):(lag+14)] <- as.numeric(tempTo[positionTo[i],2:3])\n  }\n  else {X[[1]][i,(lag+13):(lag+14)] <- 0}\n} # Done creating the 4 features for 1st lag\n\n # New features 5: 2nd level degrees\n\n# return in and out degrees of all vertexes\n\nnodeInDeg <- degree(graph=graphList[[lag]],mode='in')\nnodeOutDeg <- degree(graph=graphList[[lag]],mode='out')\n\n# length(nodeInDeg)\nhead(nodeInDeg)\nis.vector(nodeInDeg)\nsum(nodeInDeg)\n\n# This will return a list of adjacent vertices to a vertex\nadjNodeIn <- get.adjlist(graph=graphList[[lag]],mode=\"in\")\nadjNodeOut <- get.adjlist(graph=graphList[[lag]],mode=\"out\")\nnodeList <- names(adjNodeIn)\n\n\nhead(adjNodeIn)\nis.vector(adjNodeIn['8434'][1])\nis.numeric(adjNodeIn['8434'][1])\nadjNodeIn['8434'][[1]][1] \n\n# Now to the features:\n\n\n# Initiate numbers of indegree of inNode, indeg of Onode, outdeg of inNode, outdeg of outNode\ninNodeInDeg <-vector()\ninNodeOutDeg <-vector()\noutNodeOutDeg <-vector()\noutNodeInDeg <-vector()\n\nadjNodeIn[1]#[[1]]\nsum(nodeInDeg[adjNodeIn[1][[1]]])\n\nfor (i in 1:length(adjNodeIn)) {\n  inNodeInDeg[i] <- sum(nodeInDeg[adjNodeIn[i][[1]]]);\n  inNodeOutDeg[i] <- sum(nodeOutDeg[adjNodeIn[i][[1]]]);\n  outNodeOutDeg [i]  <- sum(nodeOutDeg[adjNodeOut[i][[1]]]);\n  outNodeInDeg [i]  <- sum(nodeInDeg[adjNodeOut[i][[1]]]);\n}\nedgeListStr[[lag]]\n\nposFrom <- match(x=edgeListStr[[lag]][,1],table=nodeList )\nposTo <- match(x=edgeListStr[[lag]][,2],table=nodeList )\n\n\nhead(posFrom)\n### Now to put these info into the big matrix: (hard!)\ncolnames(X[[1]])[(lag+15): (lag+18)] <- c('fromSecondLevelInNodeInDeg', 'fromSecondLevelOutNodeOutDeg',\n                                          'toSecondLevelInNodeInDeg', 'toSecondLevelOutNodeOutDeg' )\n\nX[[1]][,(lag+15)] <- inNodeInDeg[posFrom]\nX[[1]][,(lag+16)] <- outNodeOutDeg[posFrom]\nX[[1]][,(lag+17)] <- inNodeInDeg[posTo]\nX[[1]][,(lag+18)] <- outNodeOutDeg[posTo]\n\nX[[1]][,lag+19] <- page.rank.old(eps=0.00001,niter=100000,graph=graphList[[lag]],vids=nodeList,directed=TRUE,\n                             damping = 0.85)[posFrom]\nX[[1]][,lag+20] <- page.rank.old(niter=100000,graph=graphList[[lag]],vids=nodeList,directed=TRUE,\n                                 damping = 0.85, eps = 0.00001)[posTo]\nhead(X[[1]])\n\n\nnames(adjNodeOut)\nadjNodeOut[names(adjNodeOut)[1000]]\nlength(adjNodeIn[4][[1]])\nnodeList[1:4]\n\n\n# Neighbourhood Discovery -------------------------------------------------\n\n  # Very useful to get \nnei <- neighborhood(graph=graphList[[lag]],order=3,mode=\"all\") #tend to be very slow\n\n\n\n# Crash on me:  label.propagation.community(graph=graphList[[lag]],)\n# Does not work on directed graph: fastgreedy\n\nhead(nei[[2]])\n\nnei[[2]]\nlength(nei)\nhead(X[[1]])\n\n# Save the feature matrix to a csv file:\nwrite.csv(x=cbind(X[[1]][,1:60],Y[[1]]),file=\"fullData39Lag.csv\")  \n\ngetwd()\n# First logistic model ----------------------------------------------------\n\nlapply(list(Y[[1]],ID[[lag]],Y[[2]],ID[[lag+1]],X[[1]][,1]), length)\n\nlogit1 <- glm(Y[[1]]~X[[1]][,2:60],family=binomial )\nsummary(logit1)\n\nfit2 <- step.up(logit1)\n\n\n\nsum(Y[[1]])-length(Y[[1]])\n#This part should not be on GitHub\n\n# Sampling and plotting ---------------------------------------------------\n\n# Sampling\ntestMat <- cbind(X[[1]][ ,c(1:24,27:28) ], Y[[1]])\nhead(testMat)\ndim(testMat)\n\ntestMat0 <- testMat[testMat[,27] == 0,]\ntestMat1 <- testMat[testMat[,27] == 1,]\nhead(testMat0)\n\n\n# Strastified sampling\ntestMatSamp <- rbind(testMat0[sample(nrow(testMat0), 100),], testMat1[sample(nrow(testMat1), 100),])\n\ncolnames(testMatSamp)[27] <- \"y\"\nhead(testMatSamp)\ndim(testMatSamp)\ntestMatSamp <- data.frame(testMatSamp)\n\n\n\n\n#Log the variable\ntestMatSampLog <- data.frame(testMatSamp)\ntestMatSampLog[20:26] <- log(testMatSamp[20:26])\n# Pair plot before log. Blue is false orange is True\npairs(main= \"Pair plot before log\", jitter(testMatSamp[19:26]), col=c(\"blue\", \"orange\")[unclass(as.factor(testMatSamp$y))] )\n# Pair plot after log\npairs(main= \"Pair plot after log\", testMatSampLog[19:26], col=c(\"blue\", \"orange\")[unclass(as.factor(testMatSampLog$y))])\n\nc(\"green3\", \"black\")[unclass(as.factor(testMatSamp$y))]\n\n                     \n                     \n                     \nsummary(logit1)\nnames(logit1)\nlogit1$R\nhead(X[[1]])\n\nedgeListStr[[1]]\n\npairs(X[[1]][,1:12], col= Y[[1]])\n\n\n\n\ndegree(graph=graphList[[1]], v=\"23231\", mode =\"in\")\n\na\n\nhead(edgeList[[1]])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Ch10: Visualization -----------------------------------------------------\n\n\n# library(RCytoscape)\n# gD.cyt <- igraph.to.graphNEL(graphList[[1]])\n# gD.cyt <- initEdgeAttribute (gD.cyt, \"weight\", 'integer', 0)\n# gDCW <- new.CytoscapeWindow(\"Les Miserables\", graph = gD.cyt, overwriteWindow = TRUE)\n# \n# # We can display graph, with defaults color/size scheme\n# displayGraph(gDCW)\n\n\n# Ch11: Small graph for illustration --------------------------------------\ninstall.packages('rgl')\nrequire(rgl)\n\n\n",
    "created" : 1392791969035.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1985568215",
    "id" : "53B11889",
    "lastKnownWriteTime" : 1393119897,
    "path" : "~/Program/Git/mat499/as-caida.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}